{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Datachecks","text":"<p>Welcome to the Datachecks Documentation!</p> <p>Let's jump to the Getting Started!</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>You can easily launch this example in just 5 minutes.</p>"},{"location":"getting_started/#installation","title":"Installation","text":""},{"location":"getting_started/#mac-os-and-linux","title":"MAC OS and Linux","text":"<p>Install Datachecks using the pip package manager. Below we are installing the package with the postgres extra, which is required for this example.</p> <pre><code>pip install 'datachecks[postgres]' -U\n</code></pre>"},{"location":"getting_started/#quick-setup-of-database-test-data","title":"Quick Setup of Database &amp; Test Data","text":"<p>Ignore if you already have a PostgreSql setup</p> Create a SQL file <p>Create a sql file named <code>init.sql</code> with the following contents: init.sql<pre><code>CREATE TABLE IF NOT EXISTS products (\nid INTEGER PRIMARY KEY,\nname TEXT,\ncategory TEXT,\ncountry_code TEXT,\nprice INTEGER\n);\nINSERT INTO products VALUES\n(1, 'Apple', 'Fruit', 'IN', 100),\n(2, 'Orange', 'Fruit', 'IN', 80),\n(3, 'Banana', 'Fruit', 'IN', 50),\n(4, 'Mango', 'Fruit', 'IN', 150),\n(5, 'Pineapple', 'Fruit', 'IN', 200),\n(6, 'Papaya', 'Fruit', 'IN', 100),\n(7, 'Grapes', 'Fruit', 'IN', 120),\n(8, 'Strawberry', 'Fruit', 'IN', 300),\n(9, 'Kiwi', 'Fruit', 'US', 200),\n(10, 'Watermelon', 'Fruit', 'US', 100);\n</code></pre></p> Postgres Docker Compose file <p>Create a <code>docker-compose.yml</code> for postgres:</p> docker-compose.yaml<pre><code>version: '3'\nservices:\ndcs-demo-postgres:\ncontainer_name: dcs-demo-postgres\nimage: postgres\nenvironment:\nPOSTGRES_DB: dcs_demo\nPOSTGRES_USER: dbuser\nPOSTGRES_PASSWORD: dbpass\nPGDATA: /data/postgres\nvolumes:\n- dcs-demo-postgres:/data/postgres\n- ./init.sql:/docker-entrypoint-initdb.d/init.sql\nports:\n- \"5431:5432\"\nnetworks:\n- dcs-demo-postgres\nrestart: unless-stopped\nnetworks:\ndcs-demo-postgres:\ndriver: bridge\nvolumes:\ndcs-demo-postgres:\ndriver: local\n</code></pre>"},{"location":"getting_started/#datachecks-configuration-file","title":"Datachecks Configuration File","text":"<p>Create a configuration file <code>dcs_config.yaml</code> with the following contents:</p> dcs_config.yaml<pre><code>data_sources:\n- name: product_db\ntype: postgres\nconnection:\nhost: 127.0.0.1\nport: 5431\nusername: dbuser\npassword: dbpass\ndatabase: dcs_demo\nmetrics:\n- name: count_of_products\nmetric_type: row_count\nresource: product_db.products\n- name: max_product_price_in_india\nmetric_type: max\nresource: product_db.products.price\nfilters:\nwhere: \"country_code = 'IN'\"\n</code></pre>"},{"location":"getting_started/#run-datachecks","title":"Run Datachecks","text":"<p>Datachecks can be run in two ways using the CLI or the Python API.</p>"},{"location":"getting_started/#run-datachecks-in-cli","title":"Run Datachecks in CLI","text":"<pre><code>datachecks inspect --config-path ./dcs_config.yaml\n</code></pre> <p>While running the above command, you should see the following output:</p> <p></p>"},{"location":"getting_started/#run-datachecks-in-python","title":"Run Datachecks in Python","text":"<pre><code>from datachecks.core import load_configuration, Inspect\nif __name__ == \"__main__\":\ninspect = Inspect(load_configuration(\"dcs_config.yaml\"))\ninspect_output = inspect.run()\nprint(inspect_output.metrics)\n# User the metrics to send or store somewhere\n# It can be sent to elk or any time series database\n</code></pre>"},{"location":"configuration/datasource_configuration/","title":"Data Source Configuration","text":"<p>Datachecks will read datasource configuration under the key <code>datasources</code> in the configuration file. User can define multiple datasource in the configuration file under <code>datasources</code> key.</p> <p>For example:</p> <pre><code>data_sources:\n- name: product_db\ntype: postgres\nconnection:\nhost: 127.0.0.1\nport: 5421\nusername: !ENV ${DB1_USER}\npassword: !ENV ${DB1_PASS}\ndatabase: dcs_db\n</code></pre>"},{"location":"configuration/datasource_configuration/#environment-variables","title":"Environment Variables","text":"<p>Datachecks supports environment variables in the configuration file. Environment variables can be used in the configuration file using the syntax <code>!ENV ${ENV_VARIABLE}</code>. For example:</p> <pre><code>data_sources:\n- name: product_db\ntype: postgres\nconnection:\nhost: !ENV ${DB_HOST}\n</code></pre>"},{"location":"configuration/datasource_configuration/#configuration-details","title":"Configuration Details","text":"Parameter Mandatory Description <code>name</code> The name of the datasource. The name should be unique. <code>type</code> The type of the datasource. Possible values are <code>postgres</code>, <code>opensearch</code> etc. Type of datasource mentioned in each supported datasource documentation <code>connection</code> The connection details of the datasource. The connection details are different for each datasource. The connection details are mentioned in each supported datasource documentation."},{"location":"configuration/metric_configuration/","title":"Metric Configuration","text":"<p>Datachecks will read metrics configuration under the key <code>metrics</code> in the configuration file. User can define multiple metrics in the configuration file under <code>metrics</code> key.</p> <p>For example:</p> <pre><code>metrics:\n- name: freshness\ntype: freshness\nresource: mysql_db.table_name.last_updated\n</code></pre>"},{"location":"configuration/metric_configuration/#configuration-details","title":"Configuration Details","text":"Parameter Mandatory Description <code>name</code> The name of the metric. The name should be unique. <code>type</code> The type of the metric. Possible values are <code>freshness</code>, <code>row_count</code> etc. Type of metric mentioned in every metric documentation <code>resource</code> The resource for which metric should be generates. A resource can be a Table, Index, Collection or Field.  In case of Table, Index or Collection the pattern of the resource name would be <code>&lt;datasource&gt;.&lt;table_name&gt;</code> or <code>&lt;datasource&gt;.&lt;index_name&gt;</code>  In case of a Field the pattern of the resource name would be <code>&lt;datasource&gt;.&lt;table_name&gt;.&lt;field_name&gt;</code> or <code>&lt;datasource&gt;.&lt;index_name&gt;.&lt;field_name&gt;</code> <code>filters</code> The filters to be applied on the resource. Filters can have <code>where</code> as a nested field.In <code>where</code> field we can pass <code>SQL Query</code>(In ase of SQl DB) or <code>Search Query</code>(In ase of search engine). For example:  <code>filters:</code> <code>where: city = 'bangalore' AND age &gt;= 30</code>"},{"location":"integrations/opensearch/","title":"OpenSearch","text":""},{"location":"integrations/opensearch/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>OpenSearch data source can be defined as below in the config file.</p> <p>The type of the data source must be <code>opensearch</code>.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n- name: opensearch_datasource\ntype: opensearch\nconfig:\nhost: localhost\nport: 9200\nuser: admin\npassword: changeme\n</code></pre>"},{"location":"integrations/postgres/","title":"PostgreSQL","text":""},{"location":"integrations/postgres/#create-a-user","title":"Create a user","text":"<p>As a super-user, please execute the following SQL commands in order to create a new group, assign a user to that group, and grant necessary permissions to access and monitor system tables.</p> <p>Please ensure that a secure password is generated and stored properly as it will be used for adding datasource in configuration file</p> <pre><code>-- Create user and group\nCREATE USER dcs_user WITH PASSWORD 'DBpass123';\nCREATE GROUP dcs_group;\nALTER GROUP dcs_group ADD USER dcs_user;\n-- Grant Postgres' monitor role to the dcs_group\nGRANT pg_monitor TO dcs_group\n</code></pre>"},{"location":"integrations/postgres/#granting-permissions-to-tables-in-a-schema","title":"Granting permissions to tables in a schema","text":"<p>For each schema, execute the following three commands to grant read-only access. Below is the example for granting access to the public schema.</p> <pre><code>-- Grant all permissions to the dcs_group\nGRANT USAGE ON SCHEMA \"public\" TO GROUP dcs_group;\nGRANT SELECT ON ALL TABLES IN SCHEMA \"public\" TO GROUP dcs_group;\nALTER DEFAULT PRIVILEGES IN SCHEMA \"public\" GRANT SELECT ON TABLES TO GROUP dcs_group;\n</code></pre>"},{"location":"integrations/postgres/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>Postgresql data source can be defined as below in the config file.</p> <pre><code># config.yaml\ndata_sources:\n- name: postgres_datasource\ntype: postgres\nconfig:\nhost: localhost\nport: 5432\nuser: dbuser\npassword: DBpass123\ndatabase: postgres\nschema: public\n</code></pre>"},{"location":"metrics/combined/","title":"Combined Metrics","text":""},{"location":"metrics/combined/#updating-soon","title":"Updating Soon ....","text":""},{"location":"metrics/completeness/","title":"Completeness Metric","text":""},{"location":"metrics/completeness/#updating-soon","title":"Updating Soon ....","text":""},{"location":"metrics/numeric_distribution/","title":"Numeric Distribution Metric","text":""},{"location":"metrics/numeric_distribution/#updating-soon","title":"Updating Soon ....","text":""},{"location":"metrics/reliability/","title":"Reliability Metrics","text":"<p>Reliability metrics are an essential tool for ensuring that your tables, indices, or collections are being updated with the most up-to-date and timely data.</p> <p>By consistently monitoring these metrics, you can gain better insights into how your systems are performing and make more informed decisions about how to optimize and improve performance. Additionally, these metrics can help you identify any potential issues or bottlenecks in your data pipelines, allowing you to take proactive steps to address them before they become major problems.</p> <p>Overall, investing in a reliable and robust set of metrics is crucial for maintaining the health and performance of your data applications and ensuring that your systems are running as smoothly and efficiently as possible.</p>"},{"location":"metrics/reliability/#freshness","title":"Freshness","text":"<p>Data freshness, also known as data timeliness, refers to the frequency at which data is updated for consumption. It is an important dimension of data quality and a pillar of data observability because recently updated data is more accurate and, therefore, more valuable.</p> <p>The resource name of freshness metric should be in the format <code>&lt;datasource&gt;.&lt;table_name&gt;.&lt;timestamp_field&gt;</code> or <code>&lt;datasource&gt;.&lt;index_name&gt;.&lt;timestamp_field&gt;</code>.</p> <p>In the below example the metric will look for the last updated timestamp of the table or index using <code>updated_at</code> field.</p> <p>Example</p> dcs_config.yaml<pre><code>metrics:\n- name: freshness_of_products\nmetric_type: freshness\nresource: product_db.products.updated_at\n</code></pre>"},{"location":"metrics/reliability/#row-count","title":"Row Count","text":"<p>The row count metric determines the total number of rows present in a table.</p> <p>Example</p> dcs_config.yaml<pre><code>metrics:\n- name: count_of_products\nmetric_type: row_count\nresource: product_db.products\nfilters:\nwhere: \"country_code = 'IN'\"\n</code></pre>"},{"location":"metrics/reliability/#document-count","title":"Document Count","text":"<p>The document count metric determines the total number of documents present in a search data source index.</p> <p>Example</p> dcs_config.yaml<pre><code>metrics:\n- name: count_of_documents\nmetric_type: document_count\nresource: search_datastore.product_data_index\n</code></pre>"},{"location":"metrics/uniqueness/","title":"Uniqueness Metrics","text":""},{"location":"metrics/uniqueness/#updating-soon","title":"Updating Soon ....","text":""},{"location":"support/contact/","title":"Contact","text":""},{"location":"support/contact/#github","title":"Github","text":"<p>Open an issue on GitHub to report bugs and ask questions.</p>"},{"location":"support/contact/#discord","title":"Discord","text":"<p>Please join our Discord Channel to chat and connect.</p>"},{"location":"support/contact/#email","title":"Email","text":"<p>Drop a mail at hi@waterdip.ai, and we will get back to you.</p>"},{"location":"support/usage_analytics/","title":"Telemetry","text":""},{"location":"support/usage_analytics/#what-is-telemetry","title":"What is Telemetry?","text":"<p>Telemetry refers to the collection of usage data. We collect some data to understand how many users we have and how they interact with Datachecks. This helps us improve the tool and prioritize implementing the new features. Below we describe what is collected, how to opt out and why we'd appreciate if you keep the telemetry on.</p>"},{"location":"support/usage_analytics/#what-data-is-collected","title":"What data is collected?","text":"<p>Datachecks collects anonymous usage data to help our team improve the tool and to apply development efforts to where our users need them most.</p> <p>We capture one event, when the inspect run is finished. No user data or potentially sensitive information is or ever will be collected. The captured data is limited to:</p> <ul> <li>Operating System and Python version</li> <li>Types of databases used (postgresql, mysql, etc.)</li> <li>Number of metrics generated</li> <li>Error message, if any, truncated to the first 20 characters.</li> </ul>"},{"location":"support/usage_analytics/#how-to-enabledisable-telemetry","title":"How to enable/disable telemetry?","text":"<p>By default, telemetry is enabled. To disable the data collection you can Set environment variable <code>DISABLE_DCS_ANONYMOUS_TELEMETRY</code> to <code>True</code></p>"},{"location":"support/usage_analytics/#should-i-opt-out","title":"Should I opt out?","text":"<p>Being open-source, we have no visibility into the tool usage unless someone actively reaches out to us or opens a GitHub issue. We\u2019d be grateful if you keep the telemetry on since it helps us answer questions like:</p> <ul> <li>How many people are actively using the tool?</li> <li>Which features are being used most?</li> <li>What is the environment you run Datachecks in?</li> </ul> <p>It helps us prioritize the development of new features and make sure we test the performance in the most popular environments.</p> <p>We understand that you might still prefer not to share any telemetry data, and we respect this wish. Follow the steps above to disable the data collection.</p>"}]}